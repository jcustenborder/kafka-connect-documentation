===========================
SpoolDirJsonSourceConnector
===========================

.. image:: SpoolDirJsonSourceConnector.svg


This connector is used to `stream <https://en.wikipedia.org/wiki/JSON_Streaming>` JSON files from a directory while converting the data based on the schema supplied in the configuration.



-------------
Configuration
-------------

-------
General
-------


^^^^^^^^^^
error.path
^^^^^^^^^^

**Importance:** High

**Type:** String

**Validator:** com.github.jcustenborder.kafka.connect.utils.config.validators.filesystem.ValidDirectoryWritable@70376c6


The directory to place files in which have error(s). This directory must exist and be writable by the user running Kafka Connect.

^^^^^^^^^^^^^
finished.path
^^^^^^^^^^^^^

**Importance:** High

**Type:** String

**Validator:** com.github.jcustenborder.kafka.connect.utils.config.validators.filesystem.ValidDirectoryWritable@2e89310c


The directory to place files that have been successfully processed. This directory must exist and be writable by the user running Kafka Connect.

^^^^^^^^^^^^^^^^^^
input.file.pattern
^^^^^^^^^^^^^^^^^^

**Importance:** High

**Type:** String


Regular expression to check input file names against. This expression must match the entire filename. The equivalent of Matcher.matches().

^^^^^^^^^^
input.path
^^^^^^^^^^

**Importance:** High

**Type:** String

**Validator:** com.github.jcustenborder.kafka.connect.utils.config.validators.filesystem.ValidDirectoryWritable@55c75b72


The directory to read files that will be processed. This directory must exist and be writable by the user running Kafka Connect.

^^^^^
topic
^^^^^

**Importance:** High

**Type:** String


The Kafka topic to write the data to.

^^^^^^^^^^^^^
halt.on.error
^^^^^^^^^^^^^

**Importance:** High

**Type:** Boolean

**Default Value:** true


Should the task halt when it encounters an error or continue to the next file.

^^^^^^^^^^
key.schema
^^^^^^^^^^

**Importance:** High

**Type:** String


The schema for the key written to Kafka.

^^^^^^^^^^^^
value.schema
^^^^^^^^^^^^

**Importance:** High

**Type:** String


The schema for the value written to Kafka.

^^^^^^^^^^^^^^^^^^^^^^^^^
schema.generation.enabled
^^^^^^^^^^^^^^^^^^^^^^^^^

**Importance:** Medium

**Type:** Boolean

**Default Value:** false


Flag to determine if schemas should be dynamically generated. If set  to true, `key.schema` and `value.schema` can be omitted, but `schema.generation.key.name` and `schema.generation.value.name` must be set.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^
schema.generation.key.fields
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

**Importance:** Medium

**Type:** List

**Default Value:** []


The field(s) to use to build a key schema. This is only used during schema generation.

^^^^^^^^^^^^^^^^^^^^^^^^^^
schema.generation.key.name
^^^^^^^^^^^^^^^^^^^^^^^^^^

**Importance:** Medium

**Type:** String

**Default Value:** com.github.jcustenborder.kafka.connect.model.Key


The name of the generated key schema.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^
schema.generation.value.name
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

**Importance:** Medium

**Type:** String

**Default Value:** com.github.jcustenborder.kafka.connect.model.Value


The name of the generated value schema.

^^^^^^^^^^^^^^^
timestamp.field
^^^^^^^^^^^^^^^

**Importance:** Medium

**Type:** String


The field in the value schema that will contain the parsed timestamp for the record. This field cannot be marked as optional and must be a [Timestamp](https://kafka.apache.org/0102/javadoc/org/apache/kafka/connect/data/Schema.html)

^^^^^^^^^^^^^^
timestamp.mode
^^^^^^^^^^^^^^

**Importance:** Medium

**Type:** String

**Default Value:** PROCESS_TIME

**Validator:** ValidEnum{enum=TimestampMode, allowed=[FIELD, FILE_TIME, PROCESS_TIME]}


Determines how the connector will set the timestamp for the [ConnectRecord](https://kafka.apache.org/0102/javadoc/org/apache/kafka/connect/connector/ConnectRecord.html#timestamp()). If set to `Field` then the timestamp will be read from a field in the value. This field cannot be optional and must be a [Timestamp](https://kafka.apache.org/0102/javadoc/org/apache/kafka/connect/data/Schema.html). Specify the field  in `timestamp.field`. If set to `FILE_TIME` then the last modified time of the file will be used. If set to `PROCESS_TIME` the time the record is read will be used.

^^^^^^^^^^
batch.size
^^^^^^^^^^

**Importance:** Low

**Type:** Int

**Default Value:** 1000


The number of records that should be returned with each batch.

^^^^^^^^^^^^^^^^^^
empty.poll.wait.ms
^^^^^^^^^^^^^^^^^^

**Importance:** Low

**Type:** Long

**Default Value:** 1000

**Validator:** [1,...,9223372036854775807]


The amount of time to wait if a poll returns an empty list of records.

^^^^^^^^^^^^^^^^^^^
file.minimum.age.ms
^^^^^^^^^^^^^^^^^^^

**Importance:** Low

**Type:** Long

**Default Value:** 0

**Validator:** [0,...,9223372036854775807]


The amount of time in milliseconds after the file was last written to before the file can be processed.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
parser.timestamp.date.formats
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

**Importance:** Low

**Type:** List

**Default Value:** [yyyy-MM-dd'T'HH:mm:ss, yyyy-MM-dd' 'HH:mm:ss]


The date formats that are expected in the file. This is a list of strings that will be used to parse the date fields in order. The most accurate date format should be the first in the list. Take a look at the Java documentation for more info. https://docs.oracle.com/javase/6/docs/api/java/text/SimpleDateFormat.html

^^^^^^^^^^^^^^^^^^^^^^^^^
parser.timestamp.timezone
^^^^^^^^^^^^^^^^^^^^^^^^^

**Importance:** Low

**Type:** String

**Default Value:** UTC


The timezone that all of the dates will be parsed with.

^^^^^^^^^^^^^^^^^^^^^^^^^
processing.file.extension
^^^^^^^^^^^^^^^^^^^^^^^^^

**Importance:** Low

**Type:** String

**Default Value:** .PROCESSING

**Validator:** ValidPattern{pattern=^.*\..+$}


Before a file is processed, it is renamed to indicate that it is currently being processed. This setting is appended to the end of the file.




--------
Examples
--------

^^^^^^^^^^^^^^^^^^^^^^
Property based example
^^^^^^^^^^^^^^^^^^^^^^


This configuration is used typically along with `standalone mode
<http://docs.confluent.io/current/connect/concepts.html#standalone-workers>`_.

.. code-block:: properties
    :name: connector.properties
    :emphasize-lines: 4,5,6,7,8

    name=SpoolDirJsonSourceConnector1
    connector.class=com.github.jcustenborder.kafka.connect.spooldir.SpoolDirJsonSourceConnector
    tasks.max=1
    error.path=< Required Configuration >
    finished.path=< Required Configuration >
    input.file.pattern=< Required Configuration >
    input.path=< Required Configuration >
    topic=< Required Configuration >




^^^^^^^^^^^^^^^^^^
Rest based example
^^^^^^^^^^^^^^^^^^


This configuration is used typically along with `distributed mode
<http://docs.confluent.io/current/connect/concepts.html#distributed-workers>`_.
Write the following json to `connector.json`, configure all of the required values, and use the command below to
post the configuration to one the distributed connect worker(s). Check here for more information about the
`Kafka Connect REST Interface. <https://docs.confluent.io/current/connect/restapi.html>`_

.. code-block:: json
    :caption: Connect Distributed REST example
    :name: connector.json
    :emphasize-lines: 6,7,8,9,10

    {
      "config" : {
        "name" : "SpoolDirJsonSourceConnector1",
        "connector.class" : "com.github.jcustenborder.kafka.connect.spooldir.SpoolDirJsonSourceConnector",
        "tasks.max" : "1",
        "error.path" : "< Required Configuration >",
        "finished.path" : "< Required Configuration >",
        "input.file.pattern" : "< Required Configuration >",
        "input.path" : "< Required Configuration >",
        "topic" : "< Required Configuration >"
      }
    }



Use curl to post the configuration to one of the Kafka Connect Workers. Change `http://localhost:8083/` the the endpoint of
one of your Kafka Connect worker(s).

.. code-block:: bash
    :caption: Create a new connector

    curl -s -X POST -H 'Content-Type: application/json' --data @connector.json http://localhost:8083/connectors


.. code-block:: bash
    :caption: Update an existing connector

    curl -s -X PUT -H 'Content-Type: application/json' --data @connector.json http://localhost:8083/connectors/SpoolDirJsonSourceConnector1/config



