========================
Kinesis Source Connector
========================

The Kinesis Source Connector is used to pull data from Amazon Kinesis and persist the data to a Kafka topic.



-------------
Configuration
-------------

-------
Kinesis
-------


^^^^^^^^^^^^^^^^^
aws.access.key.id
^^^^^^^^^^^^^^^^^

The Amazon Access Key that will be used to connect to Kinesis with.

**Importance:** High

**Type:** String



^^^^^^^^^^^^^^^^^
aws.secret.key.id
^^^^^^^^^^^^^^^^^

The Amazon Secret Key that will be used to connect to Kinesis with.

**Importance:** High

**Type:** Password



^^^^^^^^^^^^^^
kinesis.stream
^^^^^^^^^^^^^^

The Kinesis stream to read from.

**Importance:** High

**Type:** String



^^^^^^^^^^^^^^^^
kinesis.shard.id
^^^^^^^^^^^^^^^^

The shard of the Kinesis stream to read from. This is a regex which can be used to read all of the shards in the stream.

**Importance:** High

**Type:** String

**Default Value:** .*



^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
kinesis.empty.records.backoff.ms
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The number of milliseconds to backoff when the stream is empty.

**Importance:** Medium

**Type:** Long

**Default Value:** 5000

**Validator:** [500,...]



^^^^^^^^^^^^^^^^
kinesis.position
^^^^^^^^^^^^^^^^

The position in the stream to reset to if no offsets are stored.

**Importance:** Medium

**Type:** String

**Default Value:** TRIM_HORIZON

**Validator:** ``AT_SEQUENCE_NUMBER``, ``AFTER_SEQUENCE_NUMBER``, ``TRIM_HORIZON``, ``LATEST``, ``AT_TIMESTAMP``



^^^^^^^^^^^^^^^^^^^^
kinesis.record.limit
^^^^^^^^^^^^^^^^^^^^

The number of records to read in each poll of the Kinesis shard.

**Importance:** Medium

**Type:** Int

**Default Value:** 500

**Validator:** [1,...,10000]



^^^^^^^^^^^^^^
kinesis.region
^^^^^^^^^^^^^^

The AWS region for the Kinesis stream.

**Importance:** Medium

**Type:** String

**Default Value:** US_EAST_1

**Validator:** ``GovCloud``, ``US_EAST_1``, ``US_EAST_2``, ``US_WEST_1``, ``US_WEST_2``, ``EU_WEST_1``, ``EU_WEST_2``, ``EU_WEST_3``, ``EU_CENTRAL_1``, ``AP_SOUTH_1``, ``AP_SOUTHEAST_1``, ``AP_SOUTHEAST_2``, ``AP_NORTHEAST_1``, ``AP_NORTHEAST_2``, ``SA_EAST_1``, ``CN_NORTH_1``, ``CN_NORTHWEST_1``, ``CA_CENTRAL_1``



^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
kinesis.throughput.exceeded.backoff.ms
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The number of milliseconds to backoff when a throughput exceeded exception is thrown.

**Importance:** Medium

**Type:** Long

**Default Value:** 10000

**Validator:** [500,...]



-------
General
-------


^^^^^^^^^^^
kafka.topic
^^^^^^^^^^^

The kafka topic to write the data to.

**Importance:** High

**Type:** String






--------
Examples
--------

^^^^^^^^^^^^^^^^^^^^^^
Property based example
^^^^^^^^^^^^^^^^^^^^^^


This configuration is used typically along with `standalone mode
<http://docs.confluent.io/current/connect/concepts.html#standalone-workers>`_.

.. code-block:: properties
    :name: connector.properties
    :emphasize-lines: 4,5,6,7

    name=KinesisSourceConnector1
    connector.class=io.confluent.connect.kinesis.KinesisSourceConnector
    tasks.max=1
    aws.access.key.id=< Required Configuration >
    aws.secret.key.id=< Required Configuration >
    kafka.topic=< Required Configuration >
    kinesis.stream=< Required Configuration >




^^^^^^^^^^^^^^^^^^
Rest based example
^^^^^^^^^^^^^^^^^^


This configuration is used typically along with `distributed mode
<http://docs.confluent.io/current/connect/concepts.html#distributed-workers>`_.
Write the following json to `connector.json`, configure all of the required values, and use the command below to
post the configuration to one the distributed connect worker(s). Check here for more information about the
`Kafka Connect REST Interface. <https://docs.confluent.io/current/connect/restapi.html>`_

.. code-block:: json
    :caption: Connect Distributed REST example
    :name: connector.json
    :emphasize-lines: 6,7,8,9

    {
      "config" : {
        "name" : "KinesisSourceConnector1",
        "connector.class" : "io.confluent.connect.kinesis.KinesisSourceConnector",
        "tasks.max" : "1",
        "aws.access.key.id" : "< Required Configuration >",
        "aws.secret.key.id" : "< Required Configuration >",
        "kafka.topic" : "< Required Configuration >",
        "kinesis.stream" : "< Required Configuration >"
      }
    }



Use curl to post the configuration to one of the Kafka Connect Workers. Change `http://localhost:8083/` the the endpoint of
one of your Kafka Connect worker(s).

.. code-block:: bash
    :caption: Create a new connector

    curl -s -X POST -H 'Content-Type: application/json' --data @connector.json http://localhost:8083/connectors


.. code-block:: bash
    :caption: Update an existing connector

    curl -s -X PUT -H 'Content-Type: application/json' --data @connector.json http://localhost:8083/connectors/KinesisSourceConnector1/config



