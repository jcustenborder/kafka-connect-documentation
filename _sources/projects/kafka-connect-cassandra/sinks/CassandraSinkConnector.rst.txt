========================
Cassandra Sink Connector
========================

.. image:: CassandraSinkConnector.svg


The Cassandra Sink connector is used to write data to a Cassandra Cluster. This connector works by utilizing the `Batch <http://docs.datastax.com/en/drivers/java/3.0/com/datastax/driver/core/querybuilder/Batch.html>`_ functionality to write all of the records in each poll in a single batch.


.. IMPORTANT::
    This connector can be configured to manage the schema on the Cassandra cluster. When altering an existing table the key is ignored. This is due to the potential issues changing a primary key on an existing table. The key schema is used to generate a primary key for the table when it is newly created. These fields must be in the value schema as well. Data written to the table is always read from the value from Kafka. This connector uses the topic to determine the name of the table to write to. This can be changed on the fly by using a transform to change the topic name.


.. TIP::
    If you encounter error messages like this `Batch for [test.twitter] is of size 127.661KiB, exceeding specified threshold of 50.000KiB by 77.661KiB.` or warning messages like `Batch for [test.twitter] is of size 25.885KiB, exceeding specified threshold of 5.000KiB by 20.885KiB.` Try adjusting the `consumer.max.poll.records` setting in the worker.properties for Kafka Connect.


.. NOTE::
    This connector uses the topic to determine the name of the table to write to. This can be changed on the fly by using a transform like `Regex Router <https://kafka.apache.org/documentation/#connect_transforms>`_ to change the topic name.



-------------
Configuration
-------------

.. csv-table:: Configuration
    :header: "Name", "Type", "Importance", "Default Value", "Validator", "Documentation"
    :widths: auto

    "cassandra.keyspace","String","High","","","The keyspace to write to."
    "cassandra.keyspace.create.enabled","Boolean","High","true","","Flag to determine if the keyspace should be created if it does not exist."
    "cassandra.compression","String","Medium","NONE","[NONE, SNAPPY, LZ4]","Compression algorithm to use when connecting to Cassandra."
    "cassandra.consistency.level","String","Medium","LOCAL_QUORUM","ValidEnum{enum=ConsistencyLevel, allowed=[ANY, ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, SERIAL, LOCAL_SERIAL, LOCAL_ONE]}","The requested consistency level to use when writing to Cassandra."
    "cassandra.contact.points","List","Medium","[localhost]","","The hosts to connect to."
    "cassandra.deletes.enabled","Boolean","Medium","true","","Flag to determine if the connector should process deletes."
    "cassandra.password","Password","Medium","[hidden]","","The password to connect to Cassandra with."
    "cassandra.port","Int","Medium","9042","ValidPort{start=1025, end=65535}","The port the Cassandra hosts are listening on."
    "cassandra.security.enabled","Boolean","Medium","false","","Flag to determine if security is enabled."
    "cassandra.ssl.enabled","Boolean","Medium","false","","Flag to determine if SSL is enabled when connecting to Cassandra."
    "cassandra.ssl.provider","String","Medium","JDK","ValidEnum{enum=SslProvider, allowed=[JDK, OPENSSL, OPENSSL_REFCNT]}","The SSL Provider to use when connecting to Cassandra"
    "cassandra.table.create.caching","String","Medium","NONE","ValidEnum{enum=Caching, allowed=[ALL, KEYS_ONLY, ROWS_ONLY, NONE]}","Caching setting to use."
    "cassandra.table.create.compression.algorithm","String","Medium","NONE","[NONE, SNAPPY, LZ4, DEFLATE]","Compression algorithm to use when the table is created."
    "cassandra.table.create.compression.enabled","Boolean","Medium","true","","Flag to determine if compression should be used when a table is created. Existing tables are not altered."
    "cassandra.table.manage.enabled","Boolean","Medium","true","","Flag to determine if the connector should manage the table."
    "cassandra.username","String","Medium","cassandra","","The username to connect to Cassandra with."
    "cassandra.write.mode","String","Medium","Insert","ValidEnum{enum=WriteMode, allowed=[Insert, Update]}","The type of statement to build when writing to Cassandra."


^^^^^^^^^^^^^^^^^^^^^^
Property based example
^^^^^^^^^^^^^^^^^^^^^^


This configuration is used typically along with `standalone mode
<http://docs.confluent.io/current/connect/concepts.html#standalone-workers>`_.

.. code-block:: properties

    name=connector1
    tasks.max=1
    connector.class=com.github.jcustenborder.kafka.connect.cassandra.CassandraSinkConnector
    # The following values must be configured.
    cassandra.keyspace=



^^^^^^^^^^^^^^^^^^
Rest based example
^^^^^^^^^^^^^^^^^^


This configuration is used typically along with `distributed mode
<http://docs.confluent.io/current/connect/concepts.html#distributed-workers>`_.
Write the following json to `connector.json`, configure all of the required values, and use the command below to
post the configuration to one the distributed connect worker(s).

.. code-block:: json

    {
        "name": "connector1",
        "config": {
            "connector.class": "com.github.jcustenborder.kafka.connect.cassandra.CassandraSinkConnector",
            "cassandra.keyspace":"",
        }
    }

Use curl to post the configuration to one of the Kafka Connect Workers. Change `http://localhost:8083/` the the endpoint of
one of your Kafka Connect worker(s).

.. code-block:: bash

    curl -s -X POST -H 'Content-Type: application/json' --data @connector.json http://localhost:8083/connectors



